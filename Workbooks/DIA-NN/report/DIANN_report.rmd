---
title: "DIANN analysis for xyz - report"
author: "Your fancy self"
date: "`r format(Sys.Date(), '%Y-%m-%d')`"
output:
  word_document:
    fig_caption: true
mainfont: "Calibri"    
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
)
```

```{r Project Setup, echo=FALSE, warning=FALSE}
library(tidyverse)
library(purrr)
library(flextable)
library(here)
library(patchwork)
library(viridis)
library(gt)
library(plotly)

# Directory setup function
SetupDirectories <- function(suffix = "") {
  base_dir <- here::here()
  
  # Determine proteomics folder name based on suffix
  proteomics_folder <- if(suffix == "") "proteomics" else paste0("proteomics_", suffix)
  
  list(
    source = file.path(base_dir, "scripts", proteomics_folder),
    results = file.path(base_dir, "results_summary", proteomics_folder)
  )
}

# User Input
dirs <- SetupDirectories("Garima_firstpass")
results_dir <- dirs$results
source_dir <- dirs$source

results_dir_pub <- file.path(results_dir, "Publication_tables")
results_dir_pub

results_dir
# Load data
ruv_normalised_data <- readRDS(
  file.path(results_dir, "Publication_tables", "ruv_normalised_results_cln_with_replicates.RDS")
)

# Extract the components
design_matrix_report <- ruv_normalised_data@design_matrix

# Rest of the functions remain the same
ReadStudyParams <- function(filepath) {
  params_text <- readLines(filepath)
  
  params <- list()
  current_section <- NULL
  
  purrr::walk(params_text, function(line) {
    if(str_detect(line, ":$")) {
      current_section <<- str_trim(str_remove(line, ":$"))
      params[[current_section]] <<- list()
    } else if(str_detect(line, ":") && !is.null(current_section)) {
      kv <- str_split(line, ":", n = 2)[[1]]
      params[[current_section]][[str_trim(kv[1])]] <<- str_trim(kv[2])
    }
  })
  
  return(params)
}


# Sample analysis functions
CalculateSampleCounts <- function(group_summary) {
  list(
    total_samples = sum(group_summary$total_measurements),
    tech_rep_samples = group_summary |>
      filter(str_detect(group, "Pool")) |>
      pull(total_measurements) |>
      sum(),
    patient_samples = group_summary |>
      filter(!str_detect(group, "Pool")) |>
      pull(total_measurements) |>
      sum()
  )
}

CalculatePatientMetrics <- function(numbers, group_summary) {
  avg_tech_reps <- numbers$patient_samples / 
    sum(group_summary$n_samples[!str_detect(group_summary$group, "Pool")])
  
  numbers$patients_per_group <- numbers$patient_samples / avg_tech_reps
  numbers
}

ExtractStudyParameters <- function(study_params) {
  # Basic parameters (already in the function)
  basic_params <- list(
    missing_values_cutoff = as.numeric(study_params$removeRowsWithMissingValuesPercent$`Groupwise Percentage Cutoff`),
    intensity_cutoff_percentile = as.numeric(study_params$peptideIntensityFiltering$`Peptides Intensity Cutoff Percentile`),
    normalisation_method = study_params$normaliseBetweenSamples$Method,
    num_neg_ctrl = as.numeric(study_params$ruvParameters$`Num Neg Ctrl`) * 
      (as.numeric(study_params$ruvParameters$`Percentage as Neg Ctrl`)/100),
    best_k = as.numeric(study_params$ruvParameters$`Best k`)
  )
  
  # Additional peptide filtering parameters
  peptide_filtering_params <- list(
    qvalue_threshold = as.numeric(study_params$srlQvalueProteotypicPeptideClean$`Qvalue Threshold`),
    global_qvalue_threshold = as.numeric(study_params$srlQvalueProteotypicPeptideClean$`Global Qvalue Threshold`),
    proteotypic_peptide_only = as.logical(as.numeric(study_params$srlQvalueProteotypicPeptideClean$`Choose Only Proteotypic Peptide`)),
    intensity_column = study_params$srlQvalueProteotypicPeptideClean$`Input Matrix Column Ids`
  )
  
  # Intensity filtering parameters
  intensity_filtering_params <- list(
    intensity_cutoff_percentile = as.numeric(study_params$peptideIntensityFiltering$`Peptides Intensity Cutoff Percentile`),
    proportion_samples_below_cutoff = as.numeric(study_params$peptideIntensityFiltering$`Peptides Proportion of Samples Below Cutoff`)
  )
  
  # Protein peptide requirements
  protein_peptide_params <- list(
    min_peptides_per_protein = as.numeric(study_params$filterMinNumPeptidesPerProtein$`Peptides per Protein Cutoff`),
    min_peptidoforms_per_protein = as.numeric(study_params$filterMinNumPeptidesPerProtein$`Peptidoforms per Protein Cutoff`)
  )
  
  # Sample filtering parameters
  sample_filtering_params <- list(
    min_peptides_per_sample = as.numeric(study_params$filterMinNumPeptidesPerSample$`Peptides per Sample Cutoff`)
  )
  
  # Missing value parameters
  missing_value_params <- list(
    imputed_value_column = study_params$peptideMissingValueImputation$`Imputed Value Column`,
    max_proportion_missing = as.numeric(study_params$peptideMissingValueImputation$`Proportion Missing Values`)
  )
  
  # Protein missing value parameters
  protein_missing_params <- list(
    groupwise_missing_cutoff = as.numeric(study_params$removeRowsWithMissingValuesPercent$`Groupwise Percentage Cutoff`),
    max_groups_missing_cutoff = as.numeric(study_params$removeRowsWithMissingValuesPercent$`Max Groups Percentage Cutoff`),
    proteins_intensity_cutoff = as.numeric(study_params$removeRowsWithMissingValuesPercent$`Proteins Intensity Cutoff Percentile`)
  )
  
  # RUV parameters (expanded)
  ruv_params <- list(
    ruv_grouping_variable = study_params$ruvIII_C_Varying$`Ruv Grouping Variable`,
    ruv_number_k = as.numeric(study_params$ruvIII_C_Varying$`Ruv Number k`),
    percentage_as_neg_ctrl = as.numeric(study_params$ruvParameters$`Percentage as Neg Ctrl`),
    best_k = as.numeric(study_params$ruvParameters$`Best k`),
    num_neg_ctrl = as.numeric(study_params$ruvParameters$`Num Neg Ctrl`)
  )
  
  # Differential expression analysis parameters
  de_params <- list(
    formula_string = study_params$deAnalysisParameters$`Formula String`,
    treat_lfc_cutoff = as.numeric(study_params$deAnalysisParameters$`Treat Lfc Cutoff`),
    ebayes_trend = as.logical(as.character(study_params$deAnalysisParameters$`eBayes Trend`)),
    ebayes_robust = as.logical(as.character(study_params$deAnalysisParameters$`eBayes Robust`)),
    de_qvalue_threshold = as.numeric(study_params$deAnalysisParameters$`De q Val Thresh`),
    lfc_cutoff = as.logical(as.character(study_params$deAnalysisParameters$`Lfc Cutoff`))
  )
  
  # Combine all parameters
  all_params <- c(
    basic_params,
    peptide_filtering_params,
    intensity_filtering_params,
    protein_peptide_params,
    sample_filtering_params,
    missing_value_params,
    protein_missing_params,
    ruv_params,
    de_params
  )
  
  # Return all parameters
  return(all_params)
}

# Add this before the main() function
AnalyzeSamples <- function(design_matrix, study_params) {
  # Analyze group structure
  group_summary <- AnalyzeGroups(design_matrix)
  
  # Calculate basic numbers
  numbers <- CalculateSampleCounts(group_summary)
  
  # Add patient metrics
  numbers <- CalculatePatientMetrics(numbers, group_summary)
  
  # Extract study parameters
  params <- ExtractStudyParameters(study_params)
  
  # Combine parameters with numbers
  numbers <- c(numbers, params)
  
  # Return results
  list(
    numbers = numbers,
    table = group_summary
  )
}

AnalyzeGroups <- function(design_df) {
  unique(design_df$group) |>
    purrr::map_dfr(function(g) {
      group_data <- design_df |> 
        filter(group == g)
      
      tibble(
        group = g,
        n_samples = n_distinct(group_data$factor2),
        total_measurements = nrow(group_data)
      )
    })
}

```

```{r Format Sample Details, echo=FALSE}
FormatSampleDetails <- function(numbers) {
  # Check if numbers object has required fields and set defaults if missing
  if (is.null(numbers$technical_replicates)) numbers$technical_replicates <- 0
  if (is.null(numbers$biological_samples)) numbers$biological_samples <- 0
  if (is.null(numbers$total_samples)) numbers$total_samples <- 0
  if (is.null(numbers$avg_tech_reps_per_sample)) numbers$avg_tech_reps_per_sample <- 1
  
  # Handle different cases for technical replicates
  tech_rep_text <- if(numbers$technical_replicates > 0) {
    glue::glue("{numbers$biological_samples} biological samples with an average of {round(numbers$avg_tech_reps_per_sample, 2)} technical replicates per sample, and {numbers$technical_replicates} additional technical replicate measurements")
  } else {
    glue::glue("{numbers$biological_samples} biological samples with no technical replicates")
  }
  
  glue::glue("
SAMPLE DETAILS  

There are {numbers$total_samples} samples in total which consists of:  
• {tech_rep_text}  
• Sample identification (client and Salesforce ID)  
• Sample conditions upon receipt  
• Comments about any noncompliance with sample conditions or suitability for testing including client instruction to proceed/not proceed with work  ",
.trim = FALSE)
}
```

```{r Method Section, echo=FALSE}
FormatMethodDetails <- function(numbers) {
  # Set default values for missing parameters
  if (is.null(numbers$qvalue_threshold)) numbers$qvalue_threshold <- 0.01
  if (is.null(numbers$proteotypic_peptide_only)) numbers$proteotypic_peptide_only <- TRUE
  if (is.null(numbers$proportion_samples_below_cutoff)) numbers$proportion_samples_below_cutoff <- 0.5
  if (is.null(numbers$intensity_cutoff_percentile)) numbers$intensity_cutoff_percentile <- 1
  if (is.null(numbers$min_peptidoforms_per_protein)) numbers$min_peptidoforms_per_protein <- 2
  if (is.null(numbers$min_peptides_per_sample)) numbers$min_peptides_per_sample <- 200
  if (is.null(numbers$missing_values_cutoff)) numbers$missing_values_cutoff <- 33.3
  if (is.null(numbers$normalisation_method)) numbers$normalisation_method <- "cyclicloess"
  if (is.null(numbers$num_neg_ctrl)) numbers$num_neg_ctrl <- 0
  if (is.null(numbers$best_k)) numbers$best_k <- 0
  
  text <- glue::glue("
METHOD DETAILS  

Data analyses were performed based on SOP ITS-005 (DIANN).  
• SOP number(s) and name(s)  
• Brief summary of method(s):  

Data filtering and normalization
Peptide and protein quantification was performed using a series of filtering and aggregation steps to ensure high-confidence identifications and accurate quantification. Initially, low-confidence peptide identifications were removed using q-value and proteotypic peptide filtering, retaining only peptides with a q-value threshold of {numbers$qvalue_threshold} and {if(numbers$proteotypic_peptide_only) 'only those that are proteotypic' else 'including non-proteotypic peptides'}. Precursor ion intensities were then aggregated into peptide-level quantification values, combining all charge states of the same peptide sequence while keeping different modified peptides (peptidoforms) as separate entries.

Intensity threshold filtering was applied to remove peptides where a significant proportion of samples fell below a specified log-intensity threshold. By default, peptides were excluded if {numbers$proportion_samples_below_cutoff * 100}% or more of the samples were below the lowest {numbers$intensity_cutoff_percentile}st percentile of intensity values. Proteins were required to have a minimum of {numbers$min_peptidoforms_per_protein} peptides, which could include different modifications of the same sequence, to be considered for further analysis.

Samples with fewer than {numbers$min_peptides_per_sample} peptides were removed to ensure data quality. Peptides appearing in only one replicate across all groups were also excluded to maintain measurement reproducibility. Protein-level quantification was performed using the IQ algorithm, implementing the maxLFQ algorithm to generate protein abundance values. Peptide intensities were aggregated into protein-level quantification without normalization at this stage, resulting in a protein quantification matrix with log2-transformed intensity values for each protein across all samples.

Using the protein intensity matrix, zero values were replaced with NA denoting these are missing values. Proteins with {numbers$missing_values_cutoff} percent or more of the samples with missing values or values below the {numbers$intensity_cutoff_percentile}st percentile of intensity values were discarded from the analysis. The data matrix was then log (base 2) transformed and between-sample normalization were performed using the '{numbers$normalisation_method}' method from the 'limma' R package (Ritchie et al., 2015).

To remove the batch effects from biological data, the remove unwanted variation (RUVIII-C) R package (Molania et al., 2019; Poulos et al., 2020) and information on the technical replicate samples were used to remove batch effects from the normalized data matrix.

The method relies on having a set of endogenous negative control proteins, which are proteins with little or no changes in protein abundances between different samples.

For this study, {round(numbers$num_neg_ctrl)} empirical negative control proteins (q-value < 0.05) were identified from an initial ANOVA test comparing across the technical replicate groups.

{numbers$best_k} unwanted components were selected.

At each stage of the data normalization, the samples were checked for batch effects using principal component analysis (PCA) plot and relative log-expression (RLE) plots and the distribution of the Pearson correlation of every pair of technical replicate samples were calculated.

Technical replicate samples were averaged, and the pooled reference sample removed from the subsequent analysis.

• Comments on test specific conditions information (e.g. temperature), where relevant  
• Comments on deviations, modifications, additions, or exclusions to the method(s) including the acceptance from the client to proceed with them  
• Critical reagent details where relevant; comments on laboratory materials used past their expiry date including the acceptance from the client to proceed with them  ",
.trim = FALSE)

  return(text)
}
```

```{r Result Section, echo=FALSE}
FormatResults <- function(correlation_data, figures_dir = file.path(results_dir, "protein_qc")) {
  # Set default values in case correlation_data is missing or incomplete
  total_proteins <- "N/A"
  high_corr_proteins <- "N/A"
  percent_high_corr <- "N/A"
  
  # Try to extract values if correlation_data exists and has the right structure
  tryCatch({
    if (!is.null(correlation_data) && !is.null(correlation_data$protein_data)) {
      total_proteins <- nrow(correlation_data$protein_data)
      high_corr_proteins <- sum(correlation_data$protein_data$pearson >= 0.8, na.rm = TRUE)
      percent_high_corr <- round(high_corr_proteins / total_proteins * 100, 1)
    }
  }, error = function(e) {
    # If there's an error, keep using the default values
  })
  
  glue::glue("
RESULTS  

Quality Control Analysis  
Figure 1 shows the QC metrics across three stages of data processing:  
• Log2 normalisation (leftmost column, a, d, g)  
• Cyclic loess normalisation (centre column, b, e, h)  
• RUVIII-C normalisation (rightmost column, c, f, i)  

Principal Component Analysis  
The PCA plots (Figures 1a-c) demonstrate the effectiveness of batch effect removal:  
• Initial log2 data showed notable batch effects  
• After cyclic loess normalization, batch effects remained in PC1 but were reduced in PC2  
• Post RUVIII-C and cyclic loess normalization, batches merged effectively, suggesting successful removal of unwanted variations  

Relative Log Expression  
The RLE plots (Figures 1d-f) show progressive improvement in data quality:  
• Smaller interquartile ranges (IQR) after normalization indicate reduced technical variation  
• Final normalized data shows consistent median values near zero, suggesting successful bias removal  

Post-Processing Analysis  
After averaging technical replicates:  
• PCA plot (Figure 2) shows improved sample clustering  
• Density plots (Figure 3) indicate partial batch effect persistence, though significantly reduced  

Technical Reproducibility  
As shown in Table 1, analysis of {total_proteins} proteins revealed {high_corr_proteins} proteins ({percent_high_corr}%) with high technical reproducibility (r ≥ 0.8). The distribution of technical replicate correlations is shown in Figure 4, with the histogram demonstrating a strong right-skewed distribution centered near r = 1, indicating excellent reproducibility for the majority of proteins. The boxplot further confirms this observation, showing a tight distribution of correlation values in the upper range.  

Individual protein correlations between technical replicates are visualized in Figure 5, showing scatter plots for the most highly reproducible proteins (r ≥ 0.8). These plots demonstrate strong linear relationships between technical replicates, with points closely following the identity line (y=x), further confirming the robust technical reproducibility of the data.  ",
.trim = FALSE)
}
```

```{r Comment Section, echo=FALSE}
FormatComments <- function() {
  glue::glue("
COMMENTS  

Quality Control  
• All samples passed initial QC criteria  
• Normalization successfully reduced technical variation  
• Batch effects were substantially mitigated, though not completely eliminated  

Technical Performance  
• High technical reproducibility achieved for majority of proteins  
• Correlation metrics indicate reliable quantification  
• Sample processing met quality standards  

Limitations  
• Residual batch effects present but within acceptable ranges  
• Technical variation adequately controlled through normalization steps  ",
.trim = FALSE)
}
```

```{r Opinions/Interpretations Section, echo=FALSE}
FormatOpinions <- function(correlation_data) {
  # Default value
  high_corr_proteins <- "N/A"
  
  # Try to calculate if possible
  tryCatch({
    if (!is.null(correlation_data) && !is.null(correlation_data$protein_data)) {
      high_corr_proteins <- sum(correlation_data$protein_data$pearson >= 0.8, na.rm = TRUE)
    }
  }, error = function(e) {
    # Keep the default value
  })
  
  glue::glue("
OPINIONS AND INTERPRETATION  

Data Quality Assessment  
• The dataset demonstrates robust technical quality  
• Normalization strategy effectively reduced systematic biases  
• {high_corr_proteins} highly reproducible proteins provide strong foundation for biological interpretation  

Recommendations  
1. Proceed with downstream analysis using normalized dataset  
2. Consider batch information in statistical modeling  
3. Focus on highly reproducible proteins for primary conclusions  

Technical Validation  
• Quality metrics support the reliability of the data  
• Technical reproducibility meets industry standards  
• Dataset is suitable for biological interpretation  ",
.trim = FALSE)
}
```

```{r Differential Expression Section, echo=FALSE}
FormatDEDetails <- function(numbers) {
  # Set default values for missing parameters
  if (is.null(numbers$treat_lfc_cutoff)) numbers$treat_lfc_cutoff <- 0
  if (is.null(numbers$ebayes_trend)) numbers$ebayes_trend <- TRUE
  if (is.null(numbers$ebayes_robust)) numbers$ebayes_robust <- TRUE
  if (is.null(numbers$de_qvalue_threshold)) numbers$de_qvalue_threshold <- 0.05
  if (is.null(numbers$formula_string)) numbers$formula_string <- "~ 0 + group"
  
  # Determine if treat was used with a threshold
  treat_desc <- if(numbers$treat_lfc_cutoff > 0) {
    glue::glue("The treat function was used to find proteins with high confidence log fold-change, with a threshold of {numbers$treat_lfc_cutoff}.")
  } else {
    "The treat function was used to find proteins with high confidence log fold-change, with no threshold set."
  }
  
  # Determine the trend and robust settings
  trend_robust <- c()
  if(numbers$ebayes_trend) trend_robust <- c(trend_robust, "trended")
  if(numbers$ebayes_robust) trend_robust <- c(trend_robust, "robust")
  
  trend_robust_text <- if(length(trend_robust) > 0) {
    paste(paste(trend_robust, collapse = " and "), "analysis were enabled.")
  } else {
    "Standard analysis was used (no trend or robust options)."
  }
  
  glue::glue("
DIFFERENTIAL ABUNDANCE ANALYSIS

Differential abundance analysis of proteins was performed using the adjusted abundance matrix. Differential abundance analysis of proteins was performed for comparing each pair of consensus clusters. The 'limma' R package (Ritchie et al., 2015) was used, the linear model for comparing each pair of time points was fitted using the formula '{numbers$formula_string}' with the 'lmFit' function, and the p-values calculated using the empirical Bayes method 'eBayes' function. {trend_robust_text} The false discovery rate correction was applied to the moderated p-values by calculating the q-values (Storey, 2002). {treat_desc} Significant differentially expressed proteins were defined as those with q-values less than {numbers$de_qvalue_threshold}.",
.trim = FALSE)
}
```

```{r}
# Read inputs with error checking
  params_path <- file.path(dirs$source, "study_parameters.txt")
  if (!file.exists(params_path)) stop("Study parameters file not found: ", params_path)
  study_params <- ReadStudyParams(params_path)
  
```

```{r}

  matrix_path <- file.path(dirs$source, "design_matrix.tab")
  if (!file.exists(matrix_path)) stop("Design matrix file not found: ", matrix_path)
  design_matrix <- read_tsv(matrix_path)

  # Run analysis
  analysis <- tryCatch({
    AnalyzeSamples(design_matrix, study_params)
  }, error = function(e) {
    stop("Error in AnalyzeSamples: ", e$message)
  })
  
```

```{r}
# Sample analysis functions
CalculateSampleCounts <- function(group_summary) {
  # Calculate total biological samples and measurements
  total_measurements <- sum(group_summary$total_measurements)
  biological_samples <- sum(group_summary$n_samples)
  
  # Calculate technical replicates by subtracting
  # Only if total_measurements > biological_samples
  technical_replicates <- max(0, total_measurements - biological_samples)
  
  list(
    total_samples = total_measurements,
    biological_samples = biological_samples,
    technical_replicates = technical_replicates
  )
}

CalculatePatientMetrics <- function(numbers, group_summary) {
  # Calculate average number of technical replicates per biological sample
  # If there are no technical replicates, this will be 1
  avg_tech_reps_per_sample <- numbers$total_samples / numbers$biological_samples
  
  # Calculate samples per group
  samples_per_group <- numbers$biological_samples / n_distinct(group_summary$group)
  
  # Add metrics to numbers
  numbers$avg_tech_reps_per_sample <- avg_tech_reps_per_sample
  numbers$samples_per_group <- samples_per_group
  
  numbers
}

AnalyzeGroups <- function(design_df) {
  unique(design_df$group) |>
    purrr::map_dfr(function(g) {
      group_data <- design_df |> 
        filter(group == g)
      
      # Count unique Runs as biological samples
      unique_samples <- n_distinct(group_data$Run)
      
      # Count total rows as measurements (includes potential technical replicates)
      total_rows <- nrow(group_data)
      
      # Calculate average replicates based on actual data
      # If unique_samples equals total_rows, there are no technical replicates
      avg_reps <- if(unique_samples == total_rows) 1 else total_rows / unique_samples
      
      tibble(
        group = g,
        n_samples = unique_samples,
        total_measurements = total_rows,
        avg_replicates = avg_reps
      )
    })
}

# Other functions remain the same
ExtractStudyParameters <- function(study_params) {
  # Basic parameters (already in the function)
  basic_params <- list(
    missing_values_cutoff = as.numeric(study_params$removeRowsWithMissingValuesPercent$`Groupwise Percentage Cutoff`),
    intensity_cutoff_percentile = as.numeric(study_params$peptideIntensityFiltering$`Peptides Intensity Cutoff Percentile`),
    normalisation_method = study_params$normaliseBetweenSamples$Method,
    num_neg_ctrl = as.numeric(study_params$ruvParameters$`Num Neg Ctrl`) * 
      (as.numeric(study_params$ruvParameters$`Percentage as Neg Ctrl`)/100),
    best_k = as.numeric(study_params$ruvParameters$`Best k`)
  )
  
  # Additional peptide filtering parameters
  peptide_filtering_params <- list(
    qvalue_threshold = as.numeric(study_params$srlQvalueProteotypicPeptideClean$`Qvalue Threshold`),
    global_qvalue_threshold = as.numeric(study_params$srlQvalueProteotypicPeptideClean$`Global Qvalue Threshold`),
    proteotypic_peptide_only = as.logical(as.numeric(study_params$srlQvalueProteotypicPeptideClean$`Choose Only Proteotypic Peptide`)),
    intensity_column = study_params$srlQvalueProteotypicPeptideClean$`Input Matrix Column Ids`
  )
  
  # Intensity filtering parameters
  intensity_filtering_params <- list(
    intensity_cutoff_percentile = as.numeric(study_params$peptideIntensityFiltering$`Peptides Intensity Cutoff Percentile`),
    proportion_samples_below_cutoff = as.numeric(study_params$peptideIntensityFiltering$`Peptides Proportion of Samples Below Cutoff`)
  )
  
  # Protein peptide requirements
  protein_peptide_params <- list(
    min_peptides_per_protein = as.numeric(study_params$filterMinNumPeptidesPerProtein$`Peptides per Protein Cutoff`),
    min_peptidoforms_per_protein = as.numeric(study_params$filterMinNumPeptidesPerProtein$`Peptidoforms per Protein Cutoff`)
  )
  
  # Sample filtering parameters
  sample_filtering_params <- list(
    min_peptides_per_sample = as.numeric(study_params$filterMinNumPeptidesPerSample$`Peptides per Sample Cutoff`)
  )
  
  # Missing value parameters
  missing_value_params <- list(
    imputed_value_column = study_params$peptideMissingValueImputation$`Imputed Value Column`,
    max_proportion_missing = as.numeric(study_params$peptideMissingValueImputation$`Proportion Missing Values`)
  )
  
  # Protein missing value parameters
  protein_missing_params <- list(
    groupwise_missing_cutoff = as.numeric(study_params$removeRowsWithMissingValuesPercent$`Groupwise Percentage Cutoff`),
    max_groups_missing_cutoff = as.numeric(study_params$removeRowsWithMissingValuesPercent$`Max Groups Percentage Cutoff`),
    proteins_intensity_cutoff = as.numeric(study_params$removeRowsWithMissingValuesPercent$`Proteins Intensity Cutoff Percentile`)
  )
  
  # RUV parameters (expanded)
  ruv_params <- list(
    ruv_grouping_variable = study_params$ruvIII_C_Varying$`Ruv Grouping Variable`,
    ruv_number_k = as.numeric(study_params$ruvIII_C_Varying$`Ruv Number k`),
    percentage_as_neg_ctrl = as.numeric(study_params$ruvParameters$`Percentage as Neg Ctrl`),
    best_k = as.numeric(study_params$ruvParameters$`Best k`),
    num_neg_ctrl = as.numeric(study_params$ruvParameters$`Num Neg Ctrl`)
  )
  
  # Differential expression analysis parameters
  de_params <- list(
    formula_string = study_params$deAnalysisParameters$`Formula String`,
    treat_lfc_cutoff = as.numeric(study_params$deAnalysisParameters$`Treat Lfc Cutoff`),
    ebayes_trend = as.logical(as.character(study_params$deAnalysisParameters$`eBayes Trend`)),
    ebayes_robust = as.logical(as.character(study_params$deAnalysisParameters$`eBayes Robust`)),
    de_qvalue_threshold = as.numeric(study_params$deAnalysisParameters$`De q Val Thresh`),
    lfc_cutoff = as.logical(as.character(study_params$deAnalysisParameters$`Lfc Cutoff`))
  )
  
  # Combine all parameters
  all_params <- c(
    basic_params,
    peptide_filtering_params,
    intensity_filtering_params,
    protein_peptide_params,
    sample_filtering_params,
    missing_value_params,
    protein_missing_params,
    ruv_params,
    de_params
  )
  
  # Return all parameters
  return(all_params)
}

AnalyzeSamples <- function(design_matrix, study_params) {
  # Analyze group structure
  group_summary <- AnalyzeGroups(design_matrix)
  
  # Calculate basic numbers
  numbers <- CalculateSampleCounts(group_summary)
  
  # Add patient metrics
  numbers <- CalculatePatientMetrics(numbers, group_summary)
  
  # Extract study parameters
  params <- ExtractStudyParameters(study_params)
  
  # Combine parameters with numbers
  numbers <- c(numbers, params)
  
  # Return results
  list(
    numbers = numbers,
    table = group_summary
  )
}

  # Run analysis
  analysis <- tryCatch({
    AnalyzeSamples(design_matrix, study_params)
  }, error = function(e) {
    stop("Error in AnalyzeSamples: ", e$message)
  })
  
  str(analysis)


```

```{r Main Execution Function, echo=FALSE, warning=FALSE}
# Main execution function with proper document formatting
Main <- function(suffix = "") {
  # Setup directories with error checking
  dirs <- SetupDirectories(suffix)
  
  # Verify paths exist
  if (!dir.exists(dirs$source)) stop("Source directory not found: ", dirs$source)
  if (!dir.exists(dirs$results)) stop("Results directory not found: ", dirs$results)
  
  # Read inputs with error checking
  params_path <- file.path(dirs$source, "study_parameters.txt")
  if (!file.exists(params_path)) stop("Study parameters file not found: ", params_path)
  study_params <- ReadStudyParams(params_path)
  
  matrix_path <- file.path(dirs$source, "design_matrix.tab")
  if (!file.exists(matrix_path)) stop("Design matrix file not found: ", matrix_path)
  design_matrix <- read_tsv(matrix_path)
  
  corr_path <- file.path(dirs$results, "Publication_tables", "ruv_normalised_results_cln_with_replicates.RDS")
  if (!file.exists(corr_path)) stop("Correlation data file not found: ", corr_path)
  correlation_data <- readRDS(corr_path)
  
  # Run analysis
  analysis <- tryCatch({
    AnalyzeSamples(design_matrix, study_params)
  }, error = function(e) {
    stop("Error in AnalyzeSamples: ", e$message)
  })
  
  # Generate text sections
  sample_details <- tryCatch({
    FormatSampleDetails(analysis$numbers)
  }, error = function(e) {
    stop("Error in FormatSampleDetails: ", e$message)
  })
  
  method_details <- tryCatch({
    FormatMethodDetails(analysis$numbers)
  }, error = function(e) {
    stop("Error in FormatMethodDetails: ", e$message)
  })
  
 # Generate all sections
  results <- list(
    content = list(
      sample_details = FormatSampleDetails(analysis$numbers),
      method_details = FormatMethodDetails(analysis$numbers),
      results = FormatResults(correlation_data),
      comments = FormatComments(),
      opinions = FormatOpinions(correlation_data),
      de_details = FormatDEDetails(analysis$numbers)
    ),
    table = analysis$table,
    numbers = analysis$numbers
  )
  
  return(results)
}

# Execute with a specific suffix
results <- Main("Garima_firstpass")  # For "proteomics_pilot"

# Or use the default
# results <- Main()  # For just "proteomics"

# For RMarkdown output:
```
# Sample Details

`r results$content$sample_details`

# Method Details

`r results$content$method_details`

# Results

`r results$content$results`

```{r QC_metrics, echo=FALSE, warning=FALSE, fig.cap="Figure 1: QC metrics across normalisation stages"}
knitr::include_graphics(file.path(results_dir, "QC_figures", "composite_QC_figure.png"))
```


# Comments

`r results$content$comments`

# Opinions and Interpretation

`r results$content$opinions`

# Differential Expression Analysis

`r results$content$de_details`
